---
title: Introduce to apollo prediction module
categories: algorithm
tags:
  - apollo
  - autodrive
mathjax: true
comments: true
date: 2020-06-16 21:09:06
---

The prediction module studies and predicts the behavior of all the obstacles detected by the perception module. Prediction receives obstacle data along with basic perception information including positions, headings, velocities, accelerations and then generates predicted trajectories with probabilities for those obstacles.

<!-- more -->
## Input
  - **Obstacles** information from the perception module
  - **Localization** information from the localization module
  - **Planning trajectory** of the previous computing cycle from the planning module

## Output
  - Obstacles annotated with predicted trajectories and their priorities. Obstacle priority is now calculated as individual scenarios are prioritized differently. The priorities include: ignore, caution and normal (default)

## Functionalities
Based on the figure below, the prediction module comprises of 4 main functionalities: Container, Scenario, Evaluator and Predictor.
```
Localization +-------------+          +-------------+           +-------------+          +-------------+
pose         |             |          |             |           |             |          |             |
+------------>             |          |             |           |             |          |             |
Planning     |             |structured|             | Scenario  |             |Lane      |             |Predicted
trajectory   |             |obstacle  |             | type      |             |probability             |trajectory
+------------>  CONTAINER  +---------->  SCENARIO   +----------->  EVALUATOR  +---------->  PREDICTOR  +---------->
Perception   |             |          |             |           |             |          |             |
obstacles    |             |          |             |           |             |          |             |
+------------>             |          |             |           |             |          |             |
             |             |          |             |           |             |          |             |
             +-------------+          +-------------+           +-------------+          +-------------+
```

### Container

Container stores input data from subscribed channels. Current supported inputs:
- perception obstacles
- vehicle localization
- ego vehicle planning trajectory

#### Architecture

The architecture of the **container** is as below. The class `Container` defines the interface of all containers and it can't be realized because it has a pure virtual function `Insert`. `PoseContainer`, `ADCTrajectoryContainer` and  `ObstacleContainer` are derived from `Container` and realize the `Insert` function.
The `ContainerManager` class **has** many containers. It generates all three types of contianer and stores them in an unordered map to speed up the search process.
I just list some important methods of the class here, for more functions and their description, you can read the documents generated from `doxygen`.

![container](/images/2020-06-16-Introduce-to-apollo-prediction-module/container.png)

Current container contains:
- PoseContainer
- ADCTrajectoryContainer
- ObstacleContainer

#### PoseContainer
`PoseContainer` receives localization message:
- position(3d);
- theta(orientation);
- velocity(3d);

and insert ego vehicle as an obstacle into `ObstacleContainer` with id `-1` and type `VEHICLE`.

#### TrajectoryContainer
`TrajectoryContainer` receives trajectory message from planning and sets the information of current lane:
- junction id;
- the distance to junction;
- lane sequence;
- overlaps of the lane.

#### ObstacleContainer
![obstacle container](/images/2020-06-16-Introduce-to-apollo-prediction-module/container_obstacle.png)
`ObstacleContainer` structures and stores all obstacles from perception, it **has a** `LRU(Latest Recently Used)Cache` class to manage the latest recently used 10 items. The `value` of LRUCache is the obstacle and the `key`  is the id of the obstacle. The functionality of `ObstacleContainer` **depends on** the class `ObstacleCluster`, because method `SortObstacle` is used.

##### ObstacleCluster
`ObstacleCluster` contains not only `Obstcles` in an unordered map to speedup `set` and `get` but also the relationship between `Obstacles` and `LaneGraphs` from `HdMap` like `Overlaps` and `Stopsigns`.

##### Obstacle
`Obstacle` class is a basic unit to store `Obstacles` generated by `perception` module. It stores the information of a obstacle in a data structure `Feature` which is defined in google's data interchange format [protobuf](https://developers.google.com/protocol-buffers/). The proto `Feature` is as below:
```protobuf
message Lane {
  // Features of all possible current lanes.
  repeated LaneFeature current_lane_feature = 1;

  // Features of the most possible current lane.
  optional LaneFeature lane_feature = 2;

  // Features of all nearby lanes.
  repeated LaneFeature nearby_lane_feature = 3;

  // Lane graph
  optional LaneGraph lane_graph = 4;
  optional LaneGraph lane_graph_ordered = 5;

  // For modeling
  optional double label_update_time_delta = 26;
}

message LaneFeature {
  optional string lane_id = 1;
  optional uint32 lane_turn_type = 2;
  optional double lane_s = 3;
  optional double lane_l = 4;
  optional double angle_diff = 5;
  optional double dist_to_left_boundary = 6;
  optional double dist_to_right_boundary = 7;
  optional double lane_heading = 8;
  optional adu.common.hdmap.Lane.LaneType lane_type = 9;
}

message JunctionExit {
  optional string exit_lane_id = 1;
  optional adu.common.Point3D exit_position = 2;
  optional double exit_heading = 3;
  optional double exit_width = 4;
}

message JunctionFeature {
  optional string junction_id = 1;
  optional double junction_range = 2;
  optional LaneFeature enter_lane = 3;
  repeated JunctionExit junction_exit = 4;
  repeated double junction_mlp_feature = 5;
  repeated int32 junction_mlp_label = 6;  // dim is number of masks, i.e. 12
  repeated double junction_mlp_probability = 7;
  repeated string start_lane_id = 8;
}

message ObstaclePriority {
  enum Priority {
    CAUTION = 1;
    NORMAL = 2;
    IGNORE = 3;
  }
  optional Priority priority = 25 [default = NORMAL];
}

// next id = 35
message Feature {
  // Obstacle ID
  optional int32 id = 1;

  // Obstacle features
  repeated adu.common.Point3D polygon_point = 30;
  optional adu.common.Point3D position = 2;
  optional adu.common.Point3D front_position = 27;
  optional adu.common.Point3D velocity = 3;
  optional adu.common.Point3D raw_velocity = 28;  // from perception
  optional adu.common.Point3D acceleration = 4;
  optional double velocity_heading = 5;
  optional double speed = 6;
  optional double acc = 7;
  optional double theta = 8;
  optional double length = 9;
  optional double width = 10;
  optional double height = 11;
  optional double tracking_time = 12;
  optional double timestamp = 13;

  // Obstacle type-specific features
  optional Lane lane = 14;
  optional JunctionFeature junction_feature = 26;

  // Obstacle tracked features
  optional adu.common.Point3D t_position = 16;
  optional adu.common.Point3D t_velocity = 17 [deprecated = true];
  optional double t_velocity_heading = 18 [deprecated = true];
  optional double t_speed = 19 [deprecated = true];
  optional adu.common.Point3D t_acceleration = 20 [deprecated = true];
  optional double t_acc = 21 [deprecated = true];

  optional bool is_still = 22 [default = false];
  optional adu.common.perception.PerceptionObstacle.Type type = 23;
  optional double label_update_time_delta = 24;

  optional ObstaclePriority priority = 25;

  optional bool is_near_junction = 29 [default = false];

  // Obstacle ground-truth labels:
  repeated PredictionTrajectoryPoint future_trajectory_points = 31;

  // Obstacle short-term predicted trajectory points
  repeated adu.common.TrajectoryPoint
      short_term_predicted_trajectory_points = 32;

  // Obstacle predicted trajectories
  repeated Trajectory predicted_trajectory = 33;

  // ADC trajectory at the same frame
  repeated adu.common.TrajectoryPoint adc_trajectory_point = 34;
}

message ObstacleHistory {
  repeated Feature feature = 1;
  optional bool is_trainable = 2 [default = false];
}

message FrameEnv {
  optional double timestamp = 1;
  optional ObstacleHistory ego_history = 2;
  repeated ObstacleHistory obstacles_history = 3;
}
```

In addtion to the information about the obstacle, `Obstacle` uses
- a `KalmanFilter` to track the trajectory of pedestrian;
- a `KalmanFilter` to track the trajectory of other obstacles(vehicle, bicycle, etc.)
- a `DigitalFilter` to filter the heading of bicycles and pedestrians.

`Obstacle` contains many methods about obstacle's property:

###### `IsStill`: return true if the obstacle is still.
There are two checks to determine whether an obstacle is still or not:
- distance check.
- speed check.

Firstly, we can calculate the average distance deviation of an obstacle's history position:
$$
x_{avg} = \sum_{i = 1}^{n} \frac{x_{i} - x_{0}}{n - 1} \tag{1}
$$
$$
y_{avg} = \sum_{i = 1}^{n} \frac{y_{i} - y_{0}}{n - 1} \tag{2}
$$

In the above equations,
- $x_{avg}$ is the average distance deviation of $x$;
- $y_{avg}$ is the average distance deviation of $y$;
- $n$ is the history size of an obstacle, in the program is $10$;
- $x_{i}$ is the `i`th $x$ of the position in history;
- $y_{i}$ is the `i`th $y$ of the position in history;
- $x_{0}$ is the current $x$ of the position of an obstacle;
- $y_{i}$ is the current $y$ of the position of an obstacle.

Then, the speed sensibility is defined as:
$$
K_{v} = \frac{\sqrt{2 * n} * 4 * k_{std}}{(n + 1) * d_{t}} \tag{3}
$$
In the equation:
- $K_{v}$ is the sensibility of speed;
- $n$ is the history size of an obstacle;
- $k_{std}$ is the position standard deviation of an obstacle, it's $1.0$(obstacle) or $0.5$(other) in program;
- $d_{t}$ is the duration of the history.

Nextly, we calculate the distance:
$$
D = \sqrt{x_{avg}^2 + y_{avg}^2}
$$
$$
D_{std} = \sqrt{\frac{2.0}{n}} * k_{std}
$$
In the equation:
- $D$ is the distance of obstacle;
- $D_{std}$ is the standard distance of obstacle, it's $1.0$ in program;


Now we can determine the obstacle is:
- still, if $v < v_{threshold}$($v$ is current speed, $v_{threshold}$ is the threshold of speed, it's $0.8$(obstacle) or $0.5$(other) in program);
- not still, if $v > v_{threshold}$ and $K_{v} < v_{threshold}$;
- not still, if $v > v_{threshold}$ and $K_{v} > v_{threshold}$ and $D > 2.0 * D_{std}$;
- still, if $v > v_{threshold}$ and $K_{v} > v_{threshold}$ and $D < 2.0 * D_{std}$;

### Scenario

The `Scenario` sub-module analyzes scenarios that includes the ego vehicle.
Currently, two scenarios are defined:
- **Cruise** : this scenario includes Lane keeping and following.
- **Junction** : this scenario involves junctions. Junctions can either have traffic lights and/or STOP signs.

The architecture of `Scenario` is as below:
![scenario](/images/2020-06-16-Introduce-to-apollo-prediction-module/scenario.png)

#### ScenarioManager
The `ScenarioManager` class **depends on** `FeatureExtractor` to generate environment features and **depends on** `ScenarioAnalyzer` to analyze current scenario. If necessary, `ScenarioManager` will set obstacls' priorities as:
- IGNORE, if the obstacle is no need to consider;
- NORMAL, if the obstacle needs to be considered.

![priority](/images/2020-06-16-Introduce-to-apollo-prediction-module/priority.png)

The obstacle is set to `NORMAL` if the obstacle is:
- in scan area, the scan arear is a rectanglar in front of ego vehicle with the length($80$ in program) and width($12$ in program), for example, the obstacle with id of 5 is in scan area but 6 not;
- on lane, for example, the obstacle with id of 3 is on lane but 2 not;
- near junction, means that the distance between obstacle and junction is less than threshold(it's $1$ in program), see obstacle 4 and 5;
- near lane, this rule is not for the obstacle with the type of `VEHICLE`, if the distance is less than threshold($3$ in program), obstacle 2 and 3 is near lane.

Otherwise the priority of the obstacle is `IGNORE`.

#### FeatureExtractor
`FeatureExtractor` sets
- Ego lane feature, including ego lane id and s of lane;
- Left and right lane feature, including lane id and s of lane;
- Junction feature, including junction id, we only consider the junction that has signals or stop signs. 

#### ScenarioAnalyzer
`ScenarioAnalyzer` determines which scene ego vehicle is in:
- Junction, if the distance between ego vehicle and junction is less than threshold($10$ in program);
- Cruise, otherwise.

`ScenarioAnalyzer` works **depends on** `ScenarioFeatures`. Once which scenario is determined, it will generate corresponding scenario features.

#### ScenarioFeatures
`CruiseScenariosFeatures` and `CruiseScenariosFeatures` are derived from the base class `ScenarioFeatures`.

### Evaluator

The Evaluator predicts path and speed separately for any given obstacle.
An evaluator evaluates a path by outputting a probability for it (lane
sequence) using the given model stored in _prediction/data/_.

There exists 5 types of evaluators, two of which were added in Apollo 3.5. As Cruise and Junction scenarios have been included, their corresponding evaluators (Cruise MLP and Junction MLP) were added as well. The list of available evaluators include:

- **Cost evaluator**: probability is calculated by a set of cost functions
- **MLP evaluator**: probability is calculated using an MLP model
- **RNN evaluator**: probability is calculated using an RNN model
- **Cruise MLP + CNN-1d evaluator**: probability is calculated using a mix of MLP and CNN-1d models for the cruise scenario
- **Junction MLP evaluator**: probability is calculated using an MLP model for junction scenario


### Predictor

Predictor generates predicted trajectories for obstacles. Currently, the supported predictors include:

- **Empty**: obstacles have no predicted trajectories
- **Single lane**: Obstacles move along a single lane in highway navigation mode. Obstacles not on lane will be ignored.
- **Lane sequence**: obstacle moves along the lanes
- **Move sequence**: obstacle moves along the lanes by following its kinetic pattern
- **Free movement**: obstacle moves freely
- **Regional movement**: obstacle moves in a possible region
- **Junction**: Obstacles move toward junction exits with high probabilities
